{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9396d2b-6aa4-438d-9aca-317ae054ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load model (without top layer)\n",
    "model = Xception(weights='imagenet', include_top=False, pooling='avg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97c752d-01c7-4051-a70c-2b4e62d9bc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, max_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened() and count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Resize + convert to array\n",
    "        frame = cv2.resize(frame, (299, 299))\n",
    "        img_array = image.img_to_array(frame)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        frames.append(img_array)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac07f04-c939-4a64-b57f-763b9de4a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_deepfake(video_path):\n",
    "    frames = extract_frames(video_path)\n",
    "    if len(frames) == 0:\n",
    "        return \"Invalid or corrupted video\"\n",
    "\n",
    "    # Extract features using Xception\n",
    "    features = model.predict(frames, verbose=0)\n",
    "    avg_feature = np.mean(features, axis=0)\n",
    "\n",
    "    # Dummy classifier: If average feature value > threshold â†’ Fake\n",
    "    # (In real-world, train an actual classifier like SVM or NN)\n",
    "    fake_score = np.mean(avg_feature)\n",
    "    print(f\"Fake Score: {fake_score:.4f}\")\n",
    "    return \"FAKE\" if fake_score > 0.55 else \"REAL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2211d9-76f1-4e75-8988-2a78ac4a6416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake Score: 0.1279\n",
      "Prediction: REAL\n"
     ]
    }
   ],
   "source": [
    "video_path = 'sample_video.mp4'\n",
    "result = is_deepfake(video_path)\n",
    "print(\"Prediction:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0adcda-5356-45d7-a0df-9117b4b21874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "# Load Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('sample_video.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize (optional): for performance\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    # Convert to gray for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Simulate fake score (for now)\n",
    "        fake_score = round(random.uniform(0, 1), 2)\n",
    "        prediction = \"FAKE\" if fake_score > 0.5 else \"REAL\"\n",
    "\n",
    "        # Box color\n",
    "        box_color = (0, 0, 255) if prediction == \"FAKE\" else (0, 255, 0)\n",
    "\n",
    "        # Draw face box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), box_color, 2)\n",
    "\n",
    "        # Texts\n",
    "        label1 = f\"Prediction: {prediction}\"\n",
    "        label2 = f\"Fake Score: {fake_score}\"\n",
    "\n",
    "        # Text background box\n",
    "        cv2.rectangle(frame, (x, y - 40), (x + w, y), box_color, -1)\n",
    "\n",
    "        # Draw texts\n",
    "        cv2.putText(frame, label1, (x + 5, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, label2, (x + 5, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow(\"ðŸ§  Deepfake Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5efc06-0143-4da4-a07d-f0ce311f6c24",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "# Load Haar cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('sample_video.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Simulate Fake Score (random between 0 to 1)\n",
    "        fake_score = round(random.uniform(0, 1), 2)\n",
    "\n",
    "        # Determine prediction\n",
    "        prediction = \"FAKE\" if fake_score > 0.5 else \"REAL\"\n",
    "\n",
    "        # Draw texts\n",
    "        text1 = f\"Prediction: {prediction}\"\n",
    "        text2 = f\"Fake Score: {fake_score}\"\n",
    "\n",
    "        # Draw background rectangle for text\n",
    "        cv2.rectangle(frame, (x, y - 40), (x + w, y), (0, 255, 0), -1)\n",
    "\n",
    "        # Put text on the video\n",
    "        cv2.putText(frame, text1, (x + 5, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "        cv2.putText(frame, text2, (x + 5, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Show video frame\n",
    "    cv2.imshow(\"Deepfake Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fd7e3-6271-49d8-841a-1e621414b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load feature extractor\n",
    "feature_extractor = Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def extract_frames(video_path, max_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened() and count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (299, 299))\n",
    "        img_array = image.img_to_array(frame)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        frames.append(img_array)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def extract_feature_from_video(video_path):\n",
    "    frames = extract_frames(video_path)\n",
    "    if len(frames) == 0:\n",
    "        return None\n",
    "    features = feature_extractor.predict(frames, verbose=0)\n",
    "    avg_feature = np.mean(features, axis=0)\n",
    "    return avg_feature\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(dataset_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for label_folder, label in [('real', 0), ('fake', 1)]:\n",
    "        folder_path = os.path.join(dataset_dir, label_folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            video_path = os.path.join(folder_path, file)\n",
    "            feat = extract_feature_from_video(video_path)\n",
    "            if feat is not None:\n",
    "                features.append(feat)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load features and labels\n",
    "X, y = load_dataset(\"dataset\")\n",
    "print(\"Dataset loaded:\", X.shape, y.shape)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build classifier model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=8, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"deepfake_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b218e1-8305-4c03-96b6-fdee3fe8a92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
